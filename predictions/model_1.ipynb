{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRL Feature Map and Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data from the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\"Broncos\", \"Roosters\", \"Wests Tigers\", \"Rabbitohs\", \"Storm\", \"Eels\", \"Raiders\", \"Knights\", \"Dragons\", \"Sea Eagles\", \"Panthers\", \"Sharks\", \"Bulldogs\", \"Dolphins\", \"Titans\", \"Cowboys\", \"Warriors\"]\n",
    "variables =[\"Year\", \"Win\", \"Defense\", \"Attack\", \"Margin\", \"Home\", \"Versus\",  \"Round\"]\n",
    "years =  [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2022, 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2008'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Iterate over each year in the years list\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Extract data for the current year and store it in the years_arr dictionary\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Note: years.index(year) returns the index of the current year in the years list\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#       This index is then used to access the corresponding data for that year\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     years_arr[year] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43myears\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2008'"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store data for each year\n",
    "years_arr = {}\n",
    "\n",
    "# Open the JSON file containing NRL data\n",
    "with open('../data/nrl_data_multi_years_2.json', 'r') as file:\n",
    "    # Load JSON data from the file\n",
    "    data = json.load(file)\n",
    "    \n",
    "    # Extract NRL data from the loaded JSON\n",
    "    data = data['NRL']\n",
    "    \n",
    "    # Iterate over each year in the years list\n",
    "    for year in years:\n",
    "        # Extract data for the current year and store it in the years_arr dictionary\n",
    "        # Note: years.index(year) returns the index of the current year in the years list\n",
    "        #       This index is then used to access the corresponding data for that year\n",
    "        years_arr[year] = data[years.index(year)][str(year)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with columns representing combinations of team and variable names\n",
    "df = pd.DataFrame(columns=[f\"{team} {variable}\" for team in teams for variable in variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store data for all rounds\n",
    "all_store = []\n",
    "\n",
    "# Iterate over each year in the years list\n",
    "for year in years:\n",
    "    # Iterate over each round (assuming 26 rounds)\n",
    "    for round in range(0, 26):\n",
    "        try:\n",
    "            # Extract data for the current round\n",
    "            round_data = years_arr[year][round][str(round+1)]\n",
    "            \n",
    "            # Create an empty feature array \n",
    "            round_store = np.zeros([len(teams)*len(variables)], dtype=int)\n",
    "            round_teams = []\n",
    "            \n",
    "            # Iterate over each game in the round data\n",
    "            for game in round_data:\n",
    "                # Extract information about the game\n",
    "                h_team = game['Home']\n",
    "                h_score = int(game['Home_Score'])\n",
    "                a_team = game['Away']\n",
    "                a_score = int(game['Away_Score'])\n",
    "                \n",
    "                # Determine win or lose for each team\n",
    "                h_team_win = h_score >= a_score\n",
    "                a_team_win = a_score >= h_score\n",
    "                \n",
    "                # Determine home team status\n",
    "                h_home = 1\n",
    "                a_home = 0\n",
    "                \n",
    "                # Determine versus index\n",
    "                h_versus = teams.index(a_team)\n",
    "                a_versus = teams.index(h_team)\n",
    "                \n",
    "                # Determine defense (points let in)\n",
    "                h_team_defense = a_score\n",
    "                a_team_defense = h_score  \n",
    "                \n",
    "                # Determine attack points scored\n",
    "                h_team_attack = h_score \n",
    "                a_team_attack = a_score   \n",
    "                \n",
    "                # Determine margin\n",
    "                h_team_margin =  h_score - a_score   \n",
    "                a_team_margin =  a_score - h_score        \n",
    "                \n",
    "                # Keep track of which teams played to work out which teams had a bye \n",
    "                round_teams.append(h_team)\n",
    "                round_teams.append(a_team)\n",
    "                \n",
    "                # Find the index of the team in the overarching array \n",
    "                a_team_idx = teams.index(a_team)\n",
    "                h_team_idx = teams.index(h_team)\n",
    "                \n",
    "                # Determine feature map index\n",
    "                a_team_idx_fm = a_team_idx * len(variables)\n",
    "                h_team_idx_fm = h_team_idx * len(variables)\n",
    "                \n",
    "                # Populate the data for away team\n",
    "                round_store[a_team_idx_fm] = year\n",
    "                round_store[a_team_idx_fm+1] = a_team_win\n",
    "                round_store[a_team_idx_fm+2] = a_team_defense\n",
    "                round_store[a_team_idx_fm+3] = a_team_attack\n",
    "                round_store[a_team_idx_fm+4] = a_team_margin\n",
    "                round_store[a_team_idx_fm+5] = a_home\n",
    "                round_store[a_team_idx_fm+6] = a_versus\n",
    "                round_store[a_team_idx_fm+7] = round+1\n",
    "                \n",
    "                # Populate the data for home team\n",
    "                round_store[h_team_idx_fm] = year\n",
    "                round_store[h_team_idx_fm+1] = h_team_win\n",
    "                round_store[h_team_idx_fm+2] = h_team_defense\n",
    "                round_store[h_team_idx_fm+3] = h_team_attack\n",
    "                round_store[h_team_idx_fm+4] = h_team_margin\n",
    "                round_store[h_team_idx_fm+5] = h_home\n",
    "                round_store[h_team_idx_fm+6] = h_versus\n",
    "                round_store[h_team_idx_fm+7] = round+1\n",
    "                \n",
    "            # Determine teams with a bye\n",
    "            bye_teams = list(set(teams) - set(round_teams))\n",
    "            \n",
    "            # Assign values for teams with a bye\n",
    "            for bye_team in bye_teams:\n",
    "                b_team_idx = teams.index(bye_team)\n",
    "                b_team_idx_fm = b_team_idx * len(variables)\n",
    "                round_store[b_team_idx_fm] = year\n",
    "                round_store[b_team_idx_fm+1] = -1\n",
    "                round_store[b_team_idx_fm+2] = -1\n",
    "                round_store[b_team_idx_fm+3] = -1\n",
    "                round_store[b_team_idx_fm+4] = 0\n",
    "                round_store[b_team_idx_fm+5] = -1\n",
    "                round_store[b_team_idx_fm+6] = -1\n",
    "                round_store[b_team_idx_fm+7] = round+1\n",
    "                \n",
    "            # Append the round data to the all_store list\n",
    "            all_store.append(round_store)\n",
    "            \n",
    "            # Add the new row to the DataFrame using loc\n",
    "            df.loc[len(df)] = round_store\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_HISTORY = 3\n",
    "\n",
    "def get_game_history(year, round_, team):\n",
    "    # Filter the DataFrame by year\n",
    "    filtered_df = df[df[team + \" Year\"] == year]\n",
    "    \n",
    "    # Remove all byes from the game history\n",
    "    filtered_df = filtered_df.iloc[round_-GAME_HISTORY-1:round_-1] \n",
    "    \n",
    "    # Count number of byes\n",
    "    byes = len(filtered_df[filtered_df[team + \" Win\"] == -1])\n",
    "    \n",
    "    # Remove bye rows from the filtered DataFrame\n",
    "    filtered_df = filtered_df[filtered_df[team + \" Win\"] != -1]\n",
    "    \n",
    "    # Calculate mean values for win, defense, attack, and margin\n",
    "    win = filtered_df[team + \" Win\"].mean()\n",
    "    defense = filtered_df[team + \" Defense\"].median()\n",
    "    attack = filtered_df[team + \" Attack\"].median()\n",
    "    margin = filtered_df[team + \" Margin\"].median()\n",
    "    \n",
    "    # Calculate mean values for defense, attack, and margin\n",
    "    defense_mean = filtered_df[team + \" Defense\"].mean()\n",
    "    attack_mean = filtered_df[team + \" Attack\"].mean()\n",
    "    margin_mean = filtered_df[team + \" Margin\"].mean()\n",
    "    \n",
    "    # Calculate the proportion of games played at home\n",
    "    games_at_home = filtered_df[team + \" Home\"].mean()\n",
    "    \n",
    "    return win, defense, attack, margin, byes, games_at_home, defense_mean, attack_mean, margin_mean, year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Learning Data / extending upon the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "# Input: Team, Other Team Team Stats, Other Team Stats\n",
    "# Output: Team, win/lose, other team, win/lose\n",
    "\n",
    "for team in teams:\n",
    "    # Extract relevant columns from the DataFrame\n",
    "    versed_teams = df[team + \" Versus\"]\n",
    "    wins = df[team + \" Win\"]\n",
    "    rounds = df[team + \" Round\"]\n",
    "    years = df[team + \" Year\"]\n",
    "    margins = df[team + \" Margin\"]\n",
    "    \n",
    "    # Get the index of the current team\n",
    "    c_team_idx = teams.index(team)\n",
    "    \n",
    "    # Iterate over each game in the DataFrame\n",
    "    for versed_team, win, round, year, margin in zip(versed_teams, wins, rounds, years, margins):\n",
    "        # Skip games with byes or games with no momentum\n",
    "        if win == -1 or round <= GAME_HISTORY:\n",
    "            continue\n",
    "        \n",
    "        # Determine the winning team\n",
    "        winning_team = -1\n",
    "        if win == 1:\n",
    "            v_win_ = 0\n",
    "            winning_team = c_team_idx\n",
    "        else:\n",
    "            v_win_ = 1\n",
    "            winning_team = versed_team\n",
    "            \n",
    "        # Check if it's a big win\n",
    "        big_win = 1 if abs(margin) > 13 else 0 \n",
    "        \n",
    "        # Current team, versus team, who wins, current_team_stats, versus_team_stats\n",
    "        X.append([c_team_idx, versed_team, *get_game_history(year, round, team), *get_game_history(year, round, teams[versed_team])])\n",
    "        y.append([c_team_idx, versed_team, win, v_win_, big_win])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regressor model\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.3, shuffle=True)\n",
    "\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train, X_val, y_train, y_val = np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "# Create a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5))\n",
    "\n",
    "# Training loop to track R-squared scores on both training and validation sets\n",
    "num_epochs = 1000  # You can adjust the number of epochs as needed\n",
    "# Define a learning rate schedule\n",
    "initial_learning_rate = 0.00001\n",
    "final_learning_rate = 0.001\n",
    "batch_size = 32\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/num_epochs)\n",
    "steps_per_epoch = int(len(X_train_scaled)/batch_size)\n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)\n",
    "previous_loss = None\n",
    "no_loss_change_epochs = 0\n",
    "loss_change_threshold = 1e-5\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='mse')\n",
    "\n",
    "# Lists to store the R-squared scores during training\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "train_losses = []  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model on the training data\n",
    "    history = model.fit(X_train_scaled, y_train, batch_size=batch_size, epochs=1, verbose=2)\n",
    "    \n",
    "    # Calculate R-squared scores on the training and validation sets\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Store the R-squared scores for each epoch\n",
    "    train_r2_scores.append(train_r2)\n",
    "    val_r2_scores.append(val_r2)\n",
    "    \n",
    "    \n",
    "    train_loss = history.history['loss'][0]\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if previous_loss is not None and abs(previous_loss - train_loss) < loss_change_threshold:\n",
    "        no_loss_change_epochs += 1\n",
    "    else:\n",
    "        no_loss_change_epochs = 0\n",
    "    \n",
    "    # Set the current loss as the previous loss for the next epoch\n",
    "    previous_loss = train_loss\n",
    "    \n",
    "    # If there have been no loss changes for a certain number of consecutive epochs, stop training\n",
    "    if no_loss_change_epochs >= 5:\n",
    "        print(f\"Training stopped early at epoch {epoch + 1} due to no significant loss change.\")\n",
    "        break\n",
    "    \n",
    "\n",
    "# Final R-squared scores\n",
    "final_train_r2, final_val_r2 = train_r2_scores[-1], val_r2_scores[-1]\n",
    "\n",
    "print(f\"Final Training R-squared: {final_train_r2:.4f}\")\n",
    "print(f\"Final Validation R-squared: {final_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_r2_scores, label='Training R-squared')\n",
    "plt.plot(val_r2_scores, label='Validation R-squared')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R-squared Score')\n",
    "plt.title('R-squared Score over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of true vs. predicted values\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axs[0, 0].scatter(y_train[:, 0], y_train_pred[:, 0], alpha=0.5)\n",
    "axs[0, 0].set_title('Target 1')\n",
    "axs[0, 1].scatter(y_train[:, 1], y_train_pred[:, 1], alpha=0.5)\n",
    "axs[0, 1].set_title('Target 2')\n",
    "axs[1, 0].scatter(y_train[:, 2], y_train_pred[:, 2], alpha=0.5)\n",
    "axs[1, 0].set_title('Target 3')\n",
    "axs[1, 1].scatter(y_train[:, 3], y_train_pred[:, 3], alpha=0.5)\n",
    "axs[1, 1].set_title('Target 4')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='True Values', ylabel='Predicted Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wkd_matches = [[\"Broncos\", \"Rabbitohs\"], [\"Sharks\", \"Bulldogs\"], [\"Panthers\", \"Eels\"], [\"Raiders\", \"West Tigers\"], [\"Cowboys\", \"Knights\"], [\"Storm\", \"Warriors\"], [\"Sea Eagles\", \"Roosters\"], [\"Dolphins\", \"Dragons\"]]\n",
    "\n",
    "# Iterate over each weekend match\n",
    "for wkd_match in wkd_matches:\n",
    "    # Extract the teams\n",
    "    team_1 = int(teams.index(wkd_match[0]))\n",
    "    team_2 = int(teams.index(wkd_match[1]))\n",
    "\n",
    "    # Prepare input data for prediction\n",
    "    pred_in_2 = [team_1, team_2,  *get_game_history(2023, 22, teams[int(team_1)]), *get_game_history(2023, 22, teams[int(team_2)])]\n",
    "\n",
    "    # Get predictions from the model\n",
    "    predictions = model.predict([pred_in_2], verbose=0)\n",
    "    predictions = predictions[0]\n",
    "    \n",
    "    # Determine the winner based on predictions\n",
    "    if predictions[2] > predictions[3]:\n",
    "        print(f\"{teams[team_1]} wins\\t\\t {teams[team_1]}: {predictions[2]:.4f}\\t{teams[team_2]}: {predictions[3]:.4f}\\t\\tBig Win {predictions[4]}\")\n",
    "    else:\n",
    "        print(f\"{teams[team_2]} wins\\t\\t {teams[team_1]}: {predictions[2]:.4f}\\t{teams[team_2]}: {predictions[3]:.4f}\\t\\tBig Win {predictions[4]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
